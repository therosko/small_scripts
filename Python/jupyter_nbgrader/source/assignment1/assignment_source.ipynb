{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-47d06ae6bd361748",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "This is a very simple example of an assignment notebook. \n",
    "\n",
    "Let us imagine that we want all students in a course to receive their **individual dataset** to work with. We use the `student_id` as a **unique identifier** of the student and their dataset. In our case the **student_id** is `123`, therefor their personal **dataset** is called `123.csv`. It is stored in a **folder** called `data`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_id = '123'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-30d9bde2886a35a7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Task\n",
    "\n",
    "Implement a function `import_dataset`, which imports the dataset assigned and provided to you as a CSV file using `pandas`. The function `import_dataset` must take a single parameter that holds the basename of the CSV file (i.e., the name without file extension). The output of the function `import_dataset` should be a dataframe `data`, which represents your given CSV file.\n",
    "\n",
    "\n",
    "-----\n",
    "*Explaination:*\n",
    "\n",
    "*The task of the student is to correctly load the dataset into a dataframe. In the autograded test, we would like to compare the shape of the dataframe, created by the student, to the one we expect. \n",
    "Due to the fact that each student has an individual dataset, **it may occur that the shape of the datasets varies slightly** (e.g. different number of rows). This is why we want to run the **assert_equal** function,* \n",
    "* *using the **student solution** on the one hand and*\n",
    "* *calling an **\"answers module\"** on the other hand. The \"answers module\" consists of functions that we want to validate the students answers against.*\n",
    "\n",
    "*This way we make sure that the student answers are compared to an expected answer, based on the personal dataset they were given.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-47266c307c418d73",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def import_dataset(x):\n",
    "### BEGIN SOLUTION\n",
    "    import pandas as pd\n",
    "    path_to_file = \"data/\" + str(x) + \".csv\"\n",
    "    data = pd.read_csv(path_to_file)\n",
    "    \n",
    "### END SOLUTION\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-767c64ac20ed870c",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from nose.tools import assert_equal\n",
    "import pandas\n",
    "# make all tests that are the same for all students visible (e.g. that they have created a pandas dataframe)\n",
    "assert_equal(type(import_dataset(student_id)), pandas.core.frame.DataFrame)\n",
    "\n",
    "### BEGIN HIDDEN TESTS\n",
    "import importlib.util\n",
    "import os\n",
    "# call the created \"answers module\" using an absolute path (consider that the location and structure of the autograding function of nbgrader is different) in order to run the personalised evaluations\n",
    "spec = importlib.util.spec_from_file_location(\"hw1\", os.path.expanduser(\"~/eval_files/homework1.py\"))\n",
    "hw1 = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(hw1)\n",
    "# run the assert_equal test by calling the module and the according function\n",
    "assert_equal(import_dataset(student_id).shape, hw1.import_dataset(student_id).shape)\n",
    "### END HIDDEN TESTS"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}